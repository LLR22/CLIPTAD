{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一些用不到的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看 wifi csi 的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the file: ['imu', 'wifi']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"D:/MyCodes/all_30_3/train_data.h5\"\n",
    "\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"Keys in the file:\", list(f.keys()))\n",
    "\n",
    "f = h5py.File(file_path, 'r')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   24    0  250]\n",
      " [   2    7  250  650]\n",
      " [   3   22  650 1350]\n",
      " [   4    1 1350 1750]\n",
      " [   5    5 1750 2349]\n",
      " [   6   31 2349 2749]\n",
      " [   7   21 2749 3400]\n",
      " [   8   29 3400 3700]]\n"
     ]
    }
   ],
   "source": [
    "label = f[\"label\"]\n",
    "print(label[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wifi(self, sample_data, sample_label, target_data_len=4096, target_label_len=12):\n",
    "        \"\"\"\n",
    "        input: \n",
    "            data: seq_len * 3 * 3 * 30\n",
    "            label: n * 4\n",
    "        \n",
    "        output:\n",
    "            data: (3 * 3 * 30) * target_data_len\n",
    "            label: target_label_len * start * end * action\n",
    "        \"\"\"\n",
    "\n",
    "        # if seq_len = target_data_len:\n",
    "        ret_data = sample_data\n",
    "        ret_label_1 = sample_label\n",
    "        ret_label_2 = sample_data\n",
    "\n",
    "        duration = sample_data.size(0)\n",
    "        num_actions = sample_label.size(0)\n",
    "        pad_size = 0\n",
    "\n",
    "        # 截取或补充 data 并更新 label\n",
    "        if duration < target_data_len:\n",
    "             pad_size = target_data_len - duration\n",
    "             pad_tensor = torch.zeros((pad_size, *ret_data.shape[1:]), device=ret_data.device)\n",
    "             ret_data = torch.cat([ret_data, pad_tensor], dim = 0)\n",
    "            # TO DO update label\n",
    "             pad_label_tensor = torch.tensor([[num_actions + 1, 0, duration, target_data_len]], dtype=sample_label.dtype, device=sample_label.device)\n",
    "             ret_label_1 = torch.cat([ret_label_1, pad_label_tensor], dim=0)\n",
    "        else:\n",
    "             # 截取 data\n",
    "            ret_data = ret_data[:target_data_len, :, :, :]\n",
    "\n",
    "            # 筛选出完全超出范围的动作（start >= target_label_len）\n",
    "            valid_mask_discard = (ret_label_1[:, 2] < target_label_len)\n",
    "            ret_label_1 = ret_label_1[valid_mask_discard]\n",
    "\n",
    "            # 处理部分超出范围的动作（start < target_label_len 且 end >= target_label_len）\n",
    "            valid_mask_truncate = (ret_label_1[:, 2] < target_label_len) & (ret_label_1[:, 3] >= target_label_len)\n",
    "            ret_label_1[valid_mask_truncate, 3] = target_label_len - 1  # 截断 end\n",
    "\n",
    "        \n",
    "        # 补充 label 到固定长度，便于生成dataset, 一般 label 数量只会小于规定的label长度\n",
    "        num_actions = ret_label_1.size(0)\n",
    "        if  num_actions < target_label_len:\n",
    "            need = target_label_len - num_actions\n",
    "            for i in range(1, need + 1):\n",
    "                pad_tensor = torch.tensor(\n",
    "                    [[num_actions + i, 0, ret_data.size(0), ret_data.size(0)]],\n",
    "                    dtype=sample_label.dtype, device=sample_label.device\n",
    "                )\n",
    "                ret_label_1 = torch.cat([ret_label_1, pad_tensor], dim=0)\n",
    "        \n",
    "        # 调整形状\n",
    "        ret_label_1 = ret_label_1[:, 1:]\n",
    "        ret_data = ret_data.permute(3, 1, 2, 0)\n",
    "        ret_data = ret_data.reshape(-1, ret_data.shape[-1])  # [3*3*30, 2048]\n",
    "        ret_label_1 = ret_label_1[:, [1, 2, 0]]\n",
    "\n",
    "        # 归一化\n",
    "        if self.normalize:\n",
    "            # 实现归一化逻辑\n",
    "            pass\n",
    "\n",
    "        return ret_data, ret_label_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试wifi模态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8500, 30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "npy_file_path = r'D:\\MyCodes\\wifi-tad-data\\dataset\\smartwifi\\validation_npy\\1_sjz_0.npy'\n",
    "\n",
    "data = np.load(npy_file_path)\n",
    "\n",
    "# 打印数据\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class DatasetSingle(Dataset):\n",
    "    def __init__(self, dataset_dir=\"\", split=\"train\", normalize=False, modality=\"wifi\", device_keep_list=None):\n",
    "        super().__init__()\n",
    "        assert split in [\"train\", \"test\"], \"split must be 'train' or 'test'\"\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.split = split\n",
    "        self.normalize = normalize\n",
    "        self.device_keep_list = device_keep_list\n",
    "\n",
    "        # 设置数据文件夹路径\n",
    "        self.folder_path = \"D:/MyCodes/data/processed_data/wifi\"\n",
    "        if not os.path.exists(self.folder_path):\n",
    "            raise FileNotFoundError(f\"Folder {self.folder_path} does not exist.\")\n",
    "\n",
    "        # 获取所有 .h5 文件\n",
    "        self.data_list = [f for f in os.listdir(self.folder_path) if f.endswith('.h5')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "   \n",
    "    def process_wifi(self, sample_data, sample_label, target_data_len=4096, target_label_len=12):\n",
    "        \"\"\"\n",
    "        input: \n",
    "            data: seq_len * 3 * 3 * 30\n",
    "            label: n * 4\n",
    "        \n",
    "        output:\n",
    "            data: (3 * 3 * 30) * target_data_len\n",
    "            label: target_label_len * start * end * action\n",
    "        \"\"\"\n",
    "\n",
    "        # if seq_len = target_data_len:\n",
    "        ret_data = sample_data\n",
    "        ret_label_1 = sample_label\n",
    "        ret_label_2 = sample_data\n",
    "\n",
    "        duration = sample_data.size(0)\n",
    "        num_actions = sample_label.size(0)\n",
    "        pad_size = 0\n",
    "\n",
    "        # 截取或补充 data 并更新 label\n",
    "        if duration < target_data_len:\n",
    "             pad_size = target_data_len - duration\n",
    "             pad_tensor = torch.zeros((pad_size, *ret_data.shape[1:]), device=ret_data.device)\n",
    "             ret_data = torch.cat([ret_data, pad_tensor], dim = 0)\n",
    "            # TO DO update label\n",
    "             pad_label_tensor = torch.tensor([[num_actions + 1, 0, duration, target_data_len]], dtype=sample_label.dtype, device=sample_label.device)\n",
    "             ret_label_1 = torch.cat([ret_label_1, pad_label_tensor], dim=0)\n",
    "        else:\n",
    "             # 截取 data\n",
    "            ret_data = ret_data[:target_data_len, :, :, :]\n",
    "\n",
    "            # 筛选出完全超出范围的动作（start >= target_label_len）\n",
    "            valid_mask_discard = (ret_label_1[:, 2] < target_label_len)\n",
    "            ret_label_1 = ret_label_1[valid_mask_discard]\n",
    "\n",
    "            # 处理部分超出范围的动作（start < target_label_len 且 end >= target_label_len）\n",
    "            valid_mask_truncate = (ret_label_1[:, 2] < target_label_len) & (ret_label_1[:, 3] >= target_label_len)\n",
    "            ret_label_1[valid_mask_truncate, 3] = target_label_len - 1  # 截断 end\n",
    "\n",
    "        \n",
    "        # 补充 label 到固定长度，便于生成dataset, 一般 label 数量只会小于规定的label长度\n",
    "        num_actions = ret_label_1.size(0)\n",
    "        if  num_actions < target_label_len:\n",
    "            need = target_label_len - num_actions\n",
    "            for i in range(1, need + 1):\n",
    "                pad_tensor = torch.tensor(\n",
    "                    [[num_actions + i, 0, ret_data.size(0), ret_data.size(0)]],\n",
    "                    dtype=sample_label.dtype, device=sample_label.device\n",
    "                )\n",
    "                ret_label_1 = torch.cat([ret_label_1, pad_tensor], dim=0)\n",
    "        \n",
    "        # 调整形状\n",
    "        ret_label_1 = ret_label_1[:, 1:]\n",
    "        ret_data = ret_data.permute(3, 1, 2, 0)\n",
    "        ret_data = ret_data.reshape(-1, ret_data.shape[-1])  # [3*3*30, 2048]\n",
    "        ret_label_1 = ret_label_1[:, [1, 2, 0]]\n",
    "\n",
    "        # 实现 ancher-free 的 label\n",
    "        # ret_label_2 = -1 * np.ones(target_data_len, dtype=int)\n",
    "        # for start_time, end_time, action in ret_label_1:\n",
    "        #     ret_label_2[start_time:end_time] = action\n",
    "        #     # TODO\n",
    "            # ret_label_2[start_time] = \n",
    "            # ret_label_2[end_time] = \n",
    "\n",
    "        # 归一化\n",
    "        if self.normalize:\n",
    "            # 实现归一化逻辑\n",
    "            pass\n",
    "\n",
    "        return ret_data, ret_label_1\n",
    "    \n",
    "    # target_len = 4096\n",
    "    # def process_wifi(self, sample_data, sample_label, target_data_len=4096, target_label_len=12):\n",
    "    #     \"\"\"\n",
    "    #     input: \n",
    "    #         data: t * 3 * 3 * 30\n",
    "    #         label: n * 4\n",
    "        \n",
    "    #     output:\n",
    "    #         data: channel * target_data_len * 3 * 3\n",
    "    #         label: target_label_len * start * end * action\n",
    "    #     \"\"\"\n",
    "\n",
    "    #     # 补充 data 到固定长度，便于生成dataset\n",
    "    #     if sample_data.size(0) < target_data_len:\n",
    "    #         duration = sample_data.size(0)\n",
    "    #         pad_size = target_data_len - duration\n",
    "    #         # 确保 pad_data_tensor 的形状与 sample_data 一致\n",
    "    #         pad_data_tensor = torch.zeros((pad_size, *sample_data.shape[1:]), device=sample_data.device)\n",
    "    #         ret_data = torch.cat([sample_data, pad_data_tensor], dim=0)\n",
    "\n",
    "    #         # 补充 label\n",
    "    #         # num_actions = sample_label.size(0)\n",
    "    #         # pad_label_tensor = torch.tensor([[num_actions + 1, 0, duration, target_data_len]], dtype=sample_label.dtype, device=sample_label.device)\n",
    "    #         # ret_label = torch.cat([sample_label, pad_label_tensor], dim=0)\n",
    "    #         ret_label = sample_label\n",
    "    #     else:\n",
    "    #         ret_data = sample_data\n",
    "    #         ret_label = sample_label\n",
    "\n",
    "    #     # 补充 label 到固定长度，便于生成dataset\n",
    "    #     if ret_label.size(0) < target_label_len:\n",
    "    #         num_actions = ret_label.size(0)\n",
    "    #         need_nums_label = target_label_len - num_actions\n",
    "    #         offset = (target_data_len - sample_data.size(0)) / need_nums_label if need_nums_label > 0 else 0\n",
    "    #         ret_label_2 = ret_label  # 使用 ret_label 而不是 sample_label\n",
    "    #         for i in range(1, need_nums_label + 1):  # 修复语法错误\n",
    "    #             pad_tensor = torch.tensor(\n",
    "    #                 [[num_actions + i, 0, sample_data.size(0) + (i - 1) * offset, sample_data.size(0) + i * offset]],\n",
    "    #                 dtype=sample_label.dtype, device=sample_label.device\n",
    "    #             )\n",
    "    #             ret_label_2 = torch.cat([ret_label_2, pad_tensor], dim=0)\n",
    "    #     else:\n",
    "    #         ret_label_2 = ret_label\n",
    "\n",
    "    #     ret_label_2 = ret_label_2[:, 1:]\n",
    "\n",
    "    #     # 调整形状至与 wifi tad 的匹配\n",
    "    #     ret_data = ret_data.permute(3, 1, 2, 0)\n",
    "    #     ret_data = ret_data.reshape(-1, ret_data.shape[-1])  # [3*3*30, 2048]\n",
    "    #     ret_label_2 = ret_label_2[:, [1, 2, 0]]\n",
    "\n",
    "    #     # 归一化\n",
    "    #     if self.normalize:\n",
    "    #         # 实现归一化逻辑\n",
    "    #         pass\n",
    "\n",
    "    #     return ret_data, ret_label_2\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        try:\n",
    "            data_name = self.data_list[index]\n",
    "            data_path = os.path.join(self.folder_path, data_name)\n",
    "\n",
    "            with h5py.File(data_path, 'r') as f:\n",
    "                # 加载数\n",
    "                data_sample = f['amp'][()]  # 假设幅值数据存储在 'amp' 键下\n",
    "                label_sample = f['label'][()]  # 假设标签数据存储在 'label' 键下\n",
    "\n",
    "                # 转换为 PyTorch 张量\n",
    "                sample_data_tensor = torch.tensor(data_sample, dtype=torch.float32)\n",
    "                sample_label_tensor = torch.tensor(label_sample, dtype=torch.float32)\n",
    "\n",
    "                # 处理 wifi 信号\n",
    "                data, label = self.process_wifi(sample_data_tensor, sample_label_tensor)\n",
    "\n",
    "                return data, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {data_path}: {e}\")\n",
    "            raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DatasetSingle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetSingle\u001b[49m()\n\u001b[0;32m      4\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 将 DataLoader 转换为迭代器\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DatasetSingle' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = DatasetSingle()\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 将 DataLoader 转换为迭代器\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "# 获取一个批次\n",
    "data, label = next(data_iter)\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"Label shape:\", label.shape)\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入实际训练时的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(r'D:\\MyCodes\\XRF\\XRFV2-main')\n",
    "sys.path.append(r'D:\\MyCodes\\CLIPBased_TAD')\n",
    "from dataset.wwadl import WWADLDatasetSingle, detection_collate\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.wwadl_multi import WWADLDatasetMutiAll\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = WWADLDatasetSingle(r'D:\\MyCodes\\all_30_3', split='train', modality='wifi')\n",
    "train_dataset_multi = WWADLDatasetMutiAll(r'D:\\MyCodes\\all_30_3', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 定义 DataLoader\n",
    "batch_size = 10\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset_multi,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=detection_collate,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 DataLoader 转换为迭代器\n",
    "data_iter = iter(train_data_loader)\n",
    "\n",
    "# 获取一个批次\n",
    "data, label = next(data_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 尝试载入 wifi_tad 模型进行训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'D:\\MyCodes\\WiFi_TAD\\WiFiTAD_main')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TAD.model.tad_model import wifitad\n",
    "from TAD.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = config['training']['batch_size']\n",
    "learning_rate = config['training']['learning_rate']\n",
    "weight_decay = config['training']['weight_decay']\n",
    "max_epoch = config['training']['max_epoch']\n",
    "num_classes = config['dataset']['num_classes']\n",
    "checkpoint_path = config['training']['checkpoint_path']\n",
    "focal_loss = config['training']['focal_loss']\n",
    "random_seed = config['training']['random_seed']\n",
    "ngpu = config['ngpu']\n",
    "GLOBAL_SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "net = wifitad(in_channels=config['model']['in_channels'])\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                 lr=learning_rate,\n",
    "                                 weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding shape: torch.Size([4, 512, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5074, 2.1209],\n",
       "         [0.6845, 2.2998],\n",
       "         [0.3900, 2.3040],\n",
       "         ...,\n",
       "         [0.7362, 0.9828],\n",
       "         [0.7010, 1.5912],\n",
       "         [0.5631, 0.6824]],\n",
       "\n",
       "        [[0.7282, 1.6125],\n",
       "         [0.9122, 0.5242],\n",
       "         [0.9626, 5.7588],\n",
       "         ...,\n",
       "         [0.3029, 1.3716],\n",
       "         [1.1825, 1.2195],\n",
       "         [0.7359, 0.9288]],\n",
       "\n",
       "        [[0.5539, 1.9842],\n",
       "         [1.2792, 0.8339],\n",
       "         [0.3298, 1.8912],\n",
       "         ...,\n",
       "         [1.0266, 0.7839],\n",
       "         [0.7400, 1.6305],\n",
       "         [0.7661, 0.5536]],\n",
       "\n",
       "        [[0.5491, 2.0223],\n",
       "         [1.8312, 1.0682],\n",
       "         [1.8809, 1.5946],\n",
       "         ...,\n",
       "         [0.8926, 1.3192],\n",
       "         [0.5554, 1.0669],\n",
       "         [1.3258, 0.9371]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict = net(data['wifi'])\n",
    "output_dict['loc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型的各个模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 Embedding 模块， Embedding 使用 XRF 的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.XRF.embedding import TADEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = TADEmbedding(270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_out_wifi = embed(data['wifi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_out_wifi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_imu = TADEmbedding(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_out_imu = embed_imu(data['imu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_out_imu.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 Fusion 模块， Fusion 使用 XRF 的特征融合模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.XRF.fusion import GatedFusionAdd2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class GatedFusionAdd2(nn.Module):\n",
    "    def __init__(self, hidden_size: int):\n",
    "        \"\"\"\n",
    "        使用门控机制的模态融合模块。\n",
    "        Args:\n",
    "            hidden_size (int): 特征的隐藏维度 (C)。\n",
    "        \"\"\"\n",
    "        super(GatedFusionAdd2, self).__init__()\n",
    "        # print('hidden_size', hidden_size)\n",
    "        self.gate_linear = nn.Linear(hidden_size, hidden_size * 2)  # 1D 卷积等价于线性层\n",
    "        self.gate = nn.Sigmoid()  # 门控激活函数\n",
    "        self.fc = nn.Linear(hidden_size * 2, hidden_size)  # 融合后特征映射回 hidden_size\n",
    "\n",
    "    def forward(self, imu_features: torch.Tensor, wifi_features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        前向传播逻辑。\n",
    "        Args:\n",
    "            imu_features (torch.Tensor): IMU 模态特征，形状 (B, C, L)。\n",
    "            wifi_features (torch.Tensor): WiFi 模态特征，形状 (B, C, L)。\n",
    "        Returns:\n",
    "            torch.Tensor: 融合后的特征，形状 (B, C, L)。\n",
    "        \"\"\"\n",
    "        # 计算门控值\n",
    "        # print(imu_features.shape, wifi_features.shape)\n",
    "        # print(combined_features.shape)\n",
    "        # x = \n",
    "        \n",
    "        gate = self.gate(self.gate_linear(imu_features + wifi_features))\n",
    "        # print(\"hihihi\", gate.shape)\n",
    "        combined = torch.cat([imu_features, wifi_features], dim=-1)\n",
    "\n",
    "        fused_features = gate * combined\n",
    "\n",
    "        output = self.fc(fused_features)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion = GatedFusionAdd2(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_out_imu = embedding_out_imu.permute(0, 2, 1)\n",
    "embedding_out_wifi = embedding_out_wifi.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_out_imu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hihihi torch.Size([4, 256, 1024])\n"
     ]
    }
   ],
   "source": [
    "fusion_out = fusion(embedding_out_imu, embedding_out_wifi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 512])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试文本编码模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一些小尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "model_path = \"D:\\MyCodes\\CLIPBased_TAD\\model\\openai\\clip-vit-base-patch32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel, AutoTokenizer, AutoProcessor\n",
    "\n",
    "clip_processor = CLIPProcessor.from_pretrained(model_path)\n",
    "clip_encoder = CLIPModel.from_pretrained(model_path).requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2333, 7.0000],\n",
       "        [0.2333, 0.6000, 1.0000],\n",
       "        [0.6000, 1.0000, 5.0000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.action import id_to_attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_label_idx = label[0][0][2].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hand_action': 'Lifting cup to lips, swallowing',\n",
       " 'torso_action': 'Head tilted back',\n",
       " 'leg_action': 'Stationary standing/sitting'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_attribute[action_label_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lifting cup to lips, swallowing',\n",
       " 'Head tilted back',\n",
       " 'Stationary standing/sitting']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = []\n",
    "\n",
    "for k in id_to_attribute[action_label_idx]:\n",
    "    text_list.append(id_to_attribute[action_label_idx][k])\n",
    "\n",
    "text_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input =  clip_processor(text=text_list, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406, 10857,  1937,   531,  8847,   267, 13433,  8283, 49407],\n",
       "        [49406,  1375,  6124,   775,   893, 49407, 49407, 49407, 49407],\n",
       "        [49406, 29493,  2862,   270,  4919, 49407, 49407, 49407, 49407]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input['input_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeds = clip_encoder.get_text_features(**text_input)\n",
    "text_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1980,  0.1285, -0.2894,  ...,  0.2810,  0.0626, -0.5619],\n",
       "        [-0.0973, -0.3018, -0.3150,  ..., -0.4032, -0.0276, -0.3218],\n",
       "        [ 0.0234, -0.2164,  0.2205,  ..., -0.1949, -0.0291, -0.4148]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.VisionTransformer import VisionTransformer, ViT_wo_patch_embed, MB_ViT_v3, MB_ViT_v3_shareweight\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "\n",
    "text_self_attention = ViT_wo_patch_embed(global_pool=False, embed_dim=512, depth=1,\n",
    "                                                  num_heads=4, mlp_ratio=4, qkv_bias=True,\n",
    "                                                  norm_layer=partial(nn.LayerNorm, eps=1e-6))  # in: B*L*C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeds = text_embeds.unsqueeze(0) \n",
    "text_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeds_att, _ = text_self_attention(text_embeds)\n",
    "text_embeds_att.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将上述文本编码综合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.embeddings import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = TextEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000,  0.2660, 23.0000],\n",
       "         [ 0.2660,  0.4993, 24.0000],\n",
       "         [ 0.4993,  0.7327,  7.0000],\n",
       "         [ 0.7327,  1.0000, 22.0000]]),\n",
       " tensor([[ 0.1000,  0.4333, 13.0000],\n",
       "         [ 0.4333,  0.8000, 20.0000],\n",
       "         [ 0.8000,  1.0000, 24.0000]]),\n",
       " tensor([[0.2667, 0.6000, 1.0000],\n",
       "         [0.6000, 1.0000, 6.0000]]),\n",
       " tensor([[ 0.0333,  0.3667, 20.0000],\n",
       "         [ 0.3667,  0.5667, 14.0000],\n",
       "         [ 0.5667,  0.8000,  3.0000],\n",
       "         [ 0.8000,  1.0000,  4.0000]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = emb(label)\n",
    "out[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试在anchor-free情况下的文本编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.embeddings import TextEmbedding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_free = TextEmbedding2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = emb_free(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2048, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一些尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "B = 4\n",
    "seq_len = 2048\n",
    "d_model = 512\n",
    "\n",
    "# for every batch \n",
    "text_emb = torch.rand(seq_len, d_model)\n",
    "sig_emb = torch.rand(seq_len, d_model)\n",
    "\n",
    "text_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 2048])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "def get_logits( embeds1, embeds2, logit_scale):\n",
    "    # 计算image_features @ text_features.T相似度矩阵\n",
    "    logits_per_embeds1 = logit_scale * embeds1 @ embeds2.T\n",
    "    logits_per_embeds2 = logit_scale * embeds2 @ embeds1.T\n",
    "    return logits_per_embeds1, logits_per_embeds2\n",
    "\n",
    "logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07)).exp()\n",
    "\n",
    "logits_per_embeds1, logits_per_embeds2 = get_logits(text_emb, sig_emb, logit_scale)\n",
    "logits_per_embeds1.shape\n",
    "\n",
    "def cal_clip_loss(image_features, text_features, logit_scale=logit_scale):\n",
    "    device = image_features.device\n",
    "    logits_per_image, logits_per_text = get_logits(image_features, text_features, logit_scale)\n",
    "    labels = torch.arange(logits_per_image.shape[0], device=device, dtype=torch.long)\n",
    "    total_loss = (\n",
    "        F.cross_entropy(logits_per_image, labels) +\n",
    "        F.cross_entropy(logits_per_text, labels)\n",
    "    ) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整合 anchor-free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def clip_loss2(logits_per_image, logits_per_text):\n",
    "\n",
    "    device = logits_per_image.device\n",
    "\n",
    "    labels = torch.arange(logits_per_image.shape[0], device=device, dtype=torch.long)\n",
    "    total_loss = (\n",
    "        F.cross_entropy(logits_per_image, labels) +\n",
    "        F.cross_entropy(logits_per_text, labels)\n",
    "    ) / 2\n",
    "    \n",
    "    total_loss.to(device)\n",
    "\n",
    "    # print(\"total_loss: \", total_loss.device.type)\n",
    "    # print(device)\n",
    "    # assert total_loss.device.type == device, \"total_loss\"\n",
    "    \n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.TAD.embedding import Embedding\n",
    "from model.XRF.fusion import GatedFusionAdd2\n",
    "from model.embeddings import TextEmbedding2\n",
    "\n",
    "class CLIP(nn.Module):\n",
    "    def __init__(self, device='cuda'):\n",
    "        super(CLIP, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding_wifi = Embedding(in_channels=270, out_channels=512)\n",
    "        self.embedding_imu = Embedding(in_channels=30, out_channels=512)\n",
    "        self.fusion = GatedFusionAdd2(512)\n",
    "\n",
    "        self.embedding_text = TextEmbedding2(device=self.device)\n",
    "        # 冻结所有TextEmbedding2的参数\n",
    "        for param in self.embedding_text.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "        # self.logit_scale = torch.ones([])\n",
    "\n",
    "        \n",
    "        \n",
    "        self.to(self.device)\n",
    "        self.embedding_text.to(self.device)\n",
    "\n",
    "    \n",
    "    def forward(self, wifi, imu, text, status='train'):\n",
    "        wifi_embeds = self.embedding_wifi(wifi)\n",
    "        imu_embeds = self.embedding_imu(imu)\n",
    "\n",
    "        # wifi_embeds, imu_embeds = wifi_embeds.to(self.device), imu_embeds.to(self.device) # to debug\n",
    "\n",
    "        wifi_embeds = wifi_embeds.permute(0, 2, 1)\n",
    "        imu_embeds = imu_embeds.permute(0, 2, 1)\n",
    "        sig_embds = self.fusion(wifi_embeds, imu_embeds) # B * 2048 * 512\n",
    "\n",
    "        if status == 'train':\n",
    "            text_embeds = self.embedding_text(text) # B * 2048 * 512\n",
    "        if status == 'test':\n",
    "            text_embeds = text\n",
    "        \n",
    "        # text_embeds = text_embeds.to(self.device) # to debug\n",
    " \n",
    "        sig_embds = sig_embds.reshape(-1, 512) # (B * 2048 )* 512\n",
    "        text_embeds = text_embeds.reshape(-1, 512) # (B * 2048 )* 512\n",
    "\n",
    "        # sig_embds.to(self.device)\n",
    "        assert sig_embds.device.type == 'cuda', \"sig输入数据未迁移\"\n",
    "        # text_embeds = text_embeds.to(self.device)\n",
    "        assert text_embeds.device.type == self.device, \"text输入数据未迁移\"\n",
    "\n",
    "        # 归一化 ？ to understand\n",
    "        sig_embds = sig_embds / sig_embds.norm(dim=1, keepdim=True)  # [batch_img,512]\n",
    "        text_embeds = text_embeds / text_embeds.norm(dim=1, keepdim=True)  # [batch_text,512]\n",
    "\n",
    "        # 相似度计算\n",
    "        logits_per_sig = self.logit_scale * sig_embds @ text_embeds.T\n",
    "        logits_per_text = self.logit_scale * text_embeds @ sig_embds.T # (B * 2048) * (B * 2048)\n",
    "\n",
    "        assert logits_per_sig.device.type == self.device, \"logits_per_sig\"\n",
    "        assert logits_per_text.device.type == self.device, \"logits_per_text\"\n",
    "\n",
    "        \n",
    "\n",
    "        return logits_per_sig, logits_per_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 确保数据移至设备（若需要）\n",
    "        wifi = X['wifi']\n",
    "        imu = X['imu']\n",
    "        wifi, imu = wifi.to(device), imu.to(device)\n",
    "        text = [tensor.to(device, non_blocking=True) for tensor in y]\n",
    "        # X, y = X.to(device), y.to(device)\n",
    "        # for i, tensor in enumerate(text):\n",
    "        #   print(f\"Tensor {i} is on device: {tensor.device}\")\n",
    "\n",
    "        assert wifi.device.type == device, \"wifi\"\n",
    "        assert imu.device.type == device, \"imu\"\n",
    "        # assert text.device.type == 'cuda', \"text\"\n",
    "        \n",
    "        # 前向传播\n",
    "        sig_emb, text_emb = model(wifi, imu, text)\n",
    "        tmp_sig_emb, tmp_text_emb = sig_emb, text_emb\n",
    "\n",
    "        # intermediate_outputs = y_pred.clone() \n",
    "        # 计算损失\n",
    "        loss = loss_fn(tmp_sig_emb, tmp_text_emb)\n",
    "        assert loss.device.type == device, \"loss未迁移\"\n",
    "        \n",
    "        train_loss += loss.item()  # 累加损失\n",
    "        \n",
    "        # 反向传播\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # loss.backward(retain_graph=True)  # 移除retain_graph=True\n",
    "        \n",
    "        # for name, param in model.named_parameters():\n",
    "        #     print(f\"{name}梯度设备: {param.device.type}\") \n",
    "\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(f\"{name}有梯度设备: {param.grad.device}\")  # 应该与模型参数设备一致\n",
    "        #     else:\n",
    "        #         print(f\"{name}无梯度\")  # 可能未参与计算\n",
    "\n",
    "        # 检查所有参数的梯度设备\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(f\"{name}梯度设备: {param.grad.device}\")  # 应该与模型参数设备一致\n",
    "        #     else:\n",
    "        #         print(f\"{name}无梯度\")  # 可能未参与计算\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"succeed!\")\n",
    "\n",
    "    # 计算整个epoch的平均损失\n",
    "    train_loss /= len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "    \n",
    "    pass\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "  }\n",
    "\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "        train_loss = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "\n",
    "\n",
    "        # 保存训练的模型\n",
    "        model_json = model.to_json()\n",
    "        with open('./save/model.json', 'w') as file:\n",
    "            file.write(model_json)\n",
    "        # 保存训练的权重\n",
    "        model.save_weights('./save/model.h5')\n",
    "\n",
    "      # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd005361e28427b8ed7689bc8099a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hihihi\n",
      "hihihihi\n",
      "succeed!\n",
      "hihihi\n",
      "hihihihi\n",
      "succeed!\n",
      "hihihi\n",
      "hihihihi\n",
      "succeed!\n",
      "hihihi\n",
      "hihihihi\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda'  \n",
    "\n",
    "net = CLIP(device)\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    net.parameters(),\n",
    "    lr=5e-4,          # 学习率\n",
    "    weight_decay=0.1, # 权重衰减\n",
    "    betas=(0.9, 0.999) # beta1 和 beta2\n",
    ")\n",
    "\n",
    "train(net , train_data_loader, optimizer, clip_loss2, 10, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.embeddings import getTextEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text  = getTextEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), r'D:/MyCodes/CLIPBased_TAD/save/model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_per_sig:  cuda\n",
      "logits_per_text:  cuda\n"
     ]
    }
   ],
   "source": [
    "wifi = data['wifi'][0].to('cuda')  # 将 wifi 数据移动到 GPU\n",
    "imu = data['imu'][0].to('cuda')    # 将 imu 数据移动到 GPU\n",
    "text = text.to('cuda')          # 将 text 数据移动到 GPU\n",
    "\n",
    "wifi = wifi.unsqueeze(0)\n",
    "imu = imu.unsqueeze(0)\n",
    "\n",
    "out1, out2 = net(wifi, imu, text, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 90])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 anchor-based "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
