{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/yanrui/code/CLIPBased_TAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanrui/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model.models import RFCLIP\n",
    "# import embedding\n",
    "from model.CLIPTAD.CLIPModel import CLIPModel\n",
    "from model.XRF.embedding import TADEmbedding_pure\n",
    "from model.TAD.embedding import Embedding\n",
    "# fusion\n",
    "from model.fusion import GatedFusionAdd2, GatedFusionWeight\n",
    "# import backbone\n",
    "from model.TAD.tad_backbone import TADBackbone\n",
    "from configs.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 270, 2048])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "B = 2\n",
    "C1 = 270\n",
    "C2 = 30\n",
    "L = 2048\n",
    "wifi = torch.rand([B, C1, L])\n",
    "imu = torch.rand([B, C2, L])\n",
    "\n",
    "wifi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_embedding_wifi = Embedding(270)\n",
    "cnn_embedding_imu = Embedding(30)\n",
    "add_fusion = GatedFusionAdd2(512)\n",
    "weight_fusion = GatedFusionWeight(512)\n",
    "\n",
    "\n",
    "CLIPEmbed = CLIPModel(config)\n",
    "clip_embedding_wifi = CLIPEmbed.embedding_wifi\n",
    "clip_embedding_imu = CLIPEmbed.embedding_imu\n",
    "clip_fusion = CLIPEmbed.fusion # B * 512 * L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 512, 2048]), torch.Size([2, 512, 2048]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_wifi = cnn_embedding_wifi(wifi)\n",
    "cnn_imu = cnn_embedding_imu(imu)\n",
    "\n",
    "cnn_wifi.shape, cnn_imu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.XRF.fusion import GatedFusionWeight, GatedFusion, GatedFusionAdd2\n",
    "\n",
    "add_fusion = GatedFusionAdd2(512, isTrainClip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "add_fusion_res = add_fusion(cnn_wifi, cnn_imu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2048, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_fusion_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_wifi = clip_embedding_wifi(wifi)\n",
    "clip_imu = clip_embedding_imu(imu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 512, 2048]), torch.Size([2, 512, 2048]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_wifi.shape, clip_imu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.XRF.embedding import TADEmbedding_pure\n",
    "tad_emb = TADEmbedding_pure(512)\n",
    "xxx = tad_emb(add_fusion_res)\n",
    "xxx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamba_ssm.modules.mamba_simple_vim import Mamba as ViM\n",
    "from mamba_ssm.modules.mamba_simple_bim import Mamba as DBM\n",
    "\n",
    "mamba = DBM(10, d_conv=2, use_fast_path=True, expand=1)\n",
    "mamba = ViM(10, d_conv=2, bimamba_type=\"v2\", use_fast_path=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## go on test mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/yanrui/code/CLIPBased_TAD')\n",
    "\n",
    "from model.XRF.mamba_backbone import Mamba, Mamba2\n",
    "\n",
    "\n",
    "from configs.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba = Mamba2(config).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 256])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "embedd = torch.rand([2, 512, 256]).to('cuda')\n",
    "embedd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_feat = torch.rand([2, 512, 2048]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = mamba(global_feat, embedd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test mymamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
