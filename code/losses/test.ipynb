{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def generate_target_matrix(labels, batch_size, seq_len, num_classes, device):\n",
    "    multi_hot = torch.zeros((batch_size, seq_len, num_classes), device=device)\n",
    "    \n",
    "    for batch_idx in range(batch_size):\n",
    "        for action in labels[batch_idx]:\n",
    "            # 使用浮点数计算后取整\n",
    "            start_f = action[0].item() * seq_len\n",
    "            end_f = action[1].item() * seq_len\n",
    "            \n",
    "            # 新的边界计算方式\n",
    "            start = int(math.floor(start_f))\n",
    "            end = int(math.ceil(end_f))\n",
    "            \n",
    "            # 边界保护\n",
    "            start = max(0, min(start, seq_len))\n",
    "            end = max(0, min(end, seq_len))\n",
    "            if start >= end: continue\n",
    "            \n",
    "            # 标记区间（左闭右开）\n",
    "            multi_hot[batch_idx, start:end, int(action[2].item())] = 1\n",
    "\n",
    "    flattened = multi_hot.view(-1, num_classes)\n",
    "    return (flattened @ flattened.T > 0).float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_enhanced_target_matrix(labels, batch_size, seq_len, num_classes, device):\n",
    "    state_types = 3\n",
    "    multi_hot = torch.zeros((batch_size, seq_len, num_classes * state_types), device=device)\n",
    "    \n",
    "    # 填充multi_hot（保持原有逻辑不变）\n",
    "    for batch_idx in range(batch_size):\n",
    "        for action in labels[batch_idx]:\n",
    "            start_time = action[0].item()\n",
    "            end_time = action[1].item()\n",
    "            label = int(action[2].item())\n",
    "            \n",
    "            start_frame = math.floor(start_time * seq_len)\n",
    "            end_frame = math.ceil(end_time * seq_len)\n",
    "            \n",
    "            start = max(0, min(start_frame, seq_len))\n",
    "            end = max(0, min(end_frame, seq_len))\n",
    "            if start >= end: continue\n",
    "            \n",
    "            base = label * state_types\n",
    "            multi_hot[batch_idx, start, base+1] = 1  # 开始状态\n",
    "            if end - start > 1:\n",
    "                multi_hot[batch_idx, end-1, base+2] = 1  # 结束状态\n",
    "                multi_hot[batch_idx, start+1:end-1, base] = 1  # 进行中\n",
    "\n",
    "    # 展平并计算相似性矩阵\n",
    "    flattened = multi_hot.view(-1, num_classes * state_types)\n",
    "    similarity = (flattened @ flattened.T) > 0  # [B*seq_len, B*seq_len]\n",
    "\n",
    "    # 核心修正：动态生成状态兼容性掩码\n",
    "    # --------------------------------------------------------\n",
    "    # 步骤1：提取每个位置的类别和状态类型\n",
    "    active = (flattened.sum(dim=1) > 0)  # 有效位置掩码\n",
    "    channel_idx = torch.argmax(flattened, dim=1)  # 每个位置的最大激活通道\n",
    "    \n",
    "    # 类别 = 通道索引 // 3\n",
    "    class_ids = (channel_idx // state_types) * active.long()  # 无效位置设为0\n",
    "    # 状态类型 = 通道索引 % 3\n",
    "    state_idx = (channel_idx % state_types) * active.long()   # 无效位置设为0\n",
    "\n",
    "    # 步骤2：构建状态兼容性规则\n",
    "    compatibility = torch.tensor(\n",
    "        [[1,1,0], [1,1,1], [0,1,1]],  # ing/start/end的兼容规则\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # 步骤3：生成状态兼容性矩阵\n",
    "    state_mask = compatibility[state_idx][:, state_idx]  # [B*seq_len, B*seq_len]\n",
    "    \n",
    "    # 步骤4：生成类别匹配矩阵\n",
    "    class_match = (class_ids.unsqueeze(1) == class_ids.unsqueeze(0))  # [B*seq_len, B*seq_len]\n",
    "    \n",
    "    # 步骤5：组合最终掩码\n",
    "    final_mask = (state_mask & class_match & active.unsqueeze(1) & active.unsqueeze(0))\n",
    "    \n",
    "    # 应用掩码\n",
    "    return (similarity.float() * final_mask.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_target(target_matrix):\n",
    "    # 添加极小值避免全零行\n",
    "    target_matrix += 1e-8\n",
    "    # 行归一化\n",
    "    return target_matrix / target_matrix.sum(dim=1, keepdim=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 假设参数\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "num_classes = 5  # 需要根据实际标签范围确定\n",
    "device = \"cuda\"\n",
    "\n",
    "# 模拟输入数据（两个样本，每个包含两个动作）\n",
    "labels = [\n",
    "    [torch.tensor([0.0, 0.3, 2]), torch.tensor([0.5, 0.7, 3])],  # 样本1\n",
    "    [torch.tensor([0.2, 0.4, 1]), torch.tensor([0.6, 0.9, 3])]   # 样本2\n",
    "]\n",
    "\n",
    "# 生成目标矩阵\n",
    "targets = generate_target_matrix(\n",
    "    labels = labels,\n",
    "    batch_size = batch_size,\n",
    "    seq_len = seq_len,\n",
    "    num_classes = num_classes,\n",
    "    device = device\n",
    ")\n",
    "\n",
    "print(targets)  # 输出: torch.Size([20, 20]) (假设seq_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08],\n",
      "        [2.5000e-09, 2.5000e-01, 2.5000e-01, 2.5000e-09, 2.5000e-01, 2.5000e-01],\n",
      "        [2.5000e-09, 2.5000e-01, 2.5000e-01, 2.5000e-09, 2.5000e-01, 2.5000e-01],\n",
      "        [5.0000e-09, 5.0000e-09, 5.0000e-09, 5.0000e-01, 5.0000e-01, 5.0000e-09],\n",
      "        [2.0000e-09, 2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [2.5000e-09, 2.5000e-01, 2.5000e-01, 2.5000e-09, 2.5000e-01, 2.5000e-01]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "targets_nor = normalize_target(targets)\n",
    "print(targets_nor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
